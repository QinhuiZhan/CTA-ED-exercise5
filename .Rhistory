library(tidyverse) # loads dplyr, ggplot2, and others
library(stringr) # to handle text elements
library(tidytext) # includes set of functions useful for manipulating text
library(topicmodels) # to estimate topic models
library(gutenbergr) # to get text data
library(scales)
library(tm)
library(ggthemes) # to make your plots look nice
library(readr)
library(quanteda)
library(quanteda.textmodels)
#install_package(devtools)
#devtools::install_github("matthewjdenny/preText")
library(preText)
tocq  <- readRDS(gzcon(url("https://github.com/cjbarrie/CTA-ED/blob/main/data/topicmodels/tocq.RDS?raw=true")))
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>%
unnest_tokens(word, text) %>%
filter(!is.na(word)) %>%
count(booknumber, word, sort = TRUE) %>%
ungroup() %>% #remove the grouping structure generated by count()
anti_join(stop_words) #find the rows in the first data frame that do not have a match in the second data frame based on a specified key or keys
View(tocq_words)
tocq_words <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>%
unnest_tokens(word, text) %>%
filter(!is.na(word)) %>%
count(booknumber, word, sort = TRUE) %>%
ungroup() %>% #remove the grouping structure generated by count()
anti_join(stop_words) #find the rows in the first data frame that do not have a match in the second data frame based on a specified key or keys
tocq_dtm <- tocq_words %>%
cast_dtm(booknumber, word, n) # cast data into a document-term matrix format.
tm::inspect(tocq_dtm) # inspect the content of text mining objects, such as document-term matrices
View(tocq_dtm)
tocq_lda <- LDA(tocq_dtm, k = 10, control = list(seed = 1234))
tocq_topics <- tidy(tocq_lda, matrix = "beta")
head(tocq_topics, n = 10)
tocq_lda <- LDA(tocq_dtm, k = 10, control = list(seed = 1234))
tocq_lda <- LDA(tocq_dtm, k = 10, control = list(seed = 1234))
head(tocq_topics, n = 10)
tocq_lda <- LDA(tocq_dtm, k = 10, control = list(seed = 1234))
head(tocq_lda, n = 10)
tocq_top_terms <- tocq_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
tocq_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free", ncol = 4) +
scale_y_reordered() +
theme_tufte(base_family = "Helvetica")
tidy_tocq <- tocq %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
## Count most common words in both
tidy_tocq %>%
count(word, sort = TRUE)
bookfreq <- tidy_tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>%
count(booknumber, word) %>%
group_by(booknumber) %>%
mutate(proportion = n / sum(n)) %>%
select(-n) %>%
spread(booknumber, proportion)
ggplot(bookfreq, aes(x = DiA1, y = DiA2, color = abs(DiA1 - DiA2))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme_tufte(base_family = "Helvetica") +
theme(legend.position="none",
strip.background = element_blank(),
strip.text.x = element_blank()) +
labs(x = "Tocqueville DiA 2", y = "Tocqueville DiA 1") +
coord_equal()
bookfreq
tidy_tocq <- tocq %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
## Count most common words in both
tidy_tocq %>%
count(word, sort = TRUE)
bookfreq <- tidy_tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>%
mutate(word = str_extract(word, "[a-z']+")) %>% #extract only the lowercase letters [a-z] and apostrophes ' from the word column to remove any other characters from the word column.
count(booknumber, word) %>% # the occurrences of each combination of booknumber and word
group_by(booknumber) %>%
mutate(proportion = n / sum(n)) %>% #giving the proportion of each word's occurrence within its respective book
select(-n) %>% #removes the n column (the count of occurrences), leaving only the booknumber, word, and proportion columns.
spread(booknumber, proportion) #reshapes the data from long format to wide format with each unique booknumber as a separate column and the proportion values spread across these columns.
bookfreq
ggplot(bookfreq, aes(x = DiA1, y = DiA2, color = abs(DiA1 - DiA2))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme_tufte(base_family = "Helvetica") +
theme(legend.position="none",
strip.background = element_blank(),
strip.text.x = element_blank()) +
labs(x = "Tocqueville DiA 2", y = "Tocqueville DiA 1") +
coord_equal()
tocq <- tocq %>%
filter(!is.na(text))
# Divide into documents, each representing one chapter
tocq_chapter <- tocq %>%
mutate(booknumber = ifelse(gutenberg_id==815, "DiA1", "DiA2")) %>%
group_by(booknumber) %>%
mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
#regex:looks for the word "chapter" at the beginning of each string, ignoring the case of the letters
#str_detect() is a function from the stringr package used to detect patterns within strings.
ungroup() %>%
filter(chapter > 0) %>% #filters out rows where chapter isn't greater than 0
unite(document, booknumber, chapter)
#combines the booknumber and chapter columns into a new column named document, with the values separated by an underscore.
# Split into words
tocq_chapter_word <- tocq_chapter %>%
unnest_tokens(word, text)
# Find document-word counts
tocq_word_counts <- tocq_chapter_word %>%
anti_join(stop_words) %>%
count(document, word, sort = TRUE) %>%
ungroup()
tocq_word_counts
# Cast into DTM format for LDA analysis
tocq_chapters_dtm <- tocq_word_counts %>%
cast_dtm(document, word, n)
tm::inspect(tocq_chapters_dtm)
# Split into words
tocq_chapter_word <- tocq_chapter %>%
unnest_tokens(word, text)
# Find document-word counts
tocq_word_counts <- tocq_chapter_word %>%
anti_join(stop_words) %>%
count(document, word, sort = TRUE) %>%
ungroup()
tocq_word_counts
# Cast into DTM format for LDA analysis
tocq_chapters_dtm <- tocq_word_counts %>%
cast_dtm(document, word, n)
tm::inspect(tocq_chapters_dtm)
tocq_chapters_lda <- LDA(tocq_chapters_dtm, k = 2, control = list(seed = 1234))
tocq_chapters_gamma <- tidy(tocq_chapters_lda, matrix = "gamma")
tocq_chapters_gamma
